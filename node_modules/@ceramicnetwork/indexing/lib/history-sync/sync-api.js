import knex from 'knex';
import { createBlockProofsListener, } from '@ceramicnetwork/anchor-listener';
import { JobQueue } from '@ceramicnetwork/job-queue';
import { catchError, concatMap, defer, interval, mergeMap } from 'rxjs';
import { CONTINUOUS_SYNC_JOB, HISTORY_SYNC_JOB, REBUILD_ANCHOR_JOB, SyncJobType, } from './interfaces.js';
import { RebuildAnchorWorker } from './workers/rebuild-anchor.js';
import { createContinuousSyncJob, createHistorySyncJob, SyncWorker, } from './workers/sync.js';
const SYNC_STATUS_LOG_INTERVAL = 60000;
export const BLOCK_CONFIRMATIONS = 20;
export const INITIAL_INDEXING_BLOCKS = {
    'eip155:1': 16695723,
    'eip155:5': 8503000,
    'eip155:100': 26511896,
};
export const STATE_TABLE_NAME = 'ceramic_indexing_state';
export class SyncApi {
    constructor(syncConfig, ipfsService, handleCommit, localIndex, diagnosticsLogger) {
        this.syncConfig = syncConfig;
        this.ipfsService = ipfsService;
        this.handleCommit = handleCommit;
        this.localIndex = localIndex;
        this.diagnosticsLogger = diagnosticsLogger;
        this.modelsToSync = new Set();
        this.modelsToHistoricSync = new Map();
        if (!this.syncConfig.on)
            return;
        this.dataSource = knex({ client: 'pg', connection: this.syncConfig.db });
        this.jobQueue = new JobQueue(this.syncConfig.db, this.diagnosticsLogger);
    }
    async init(provider) {
        if (!this.syncConfig.on)
            return;
        this.provider = provider;
        const chainIdNumber = (await provider.getNetwork()).chainId;
        this.chainId = `eip155:${chainIdNumber}`;
        this.defaultStartBlock = INITIAL_INDEXING_BLOCKS[this.chainId] || 0;
        const [latestBlock, { processedBlockNumber }] = await Promise.all([
            this.provider.getBlock(-BLOCK_CONFIRMATIONS),
            this._initStateTable(),
            this._initModelsToSync(),
            this._initJobQueue(),
        ]);
        this.startBlock = latestBlock.number;
        this._initBlockSubscription(latestBlock.hash);
        if (processedBlockNumber == null) {
            await this._addSyncJob(HISTORY_SYNC_JOB, {
                jobType: SyncJobType.Catchup,
                fromBlock: this.defaultStartBlock,
                toBlock: latestBlock.number,
                models: Array.from(this.modelsToSync),
            });
        }
        else if (processedBlockNumber < latestBlock.number) {
            await this._addSyncJob(HISTORY_SYNC_JOB, {
                jobType: SyncJobType.Catchup,
                fromBlock: processedBlockNumber,
                toBlock: latestBlock.number,
                models: Array.from(this.modelsToSync),
            });
        }
        this._initPeriodicStatusLogger();
    }
    async _initJobQueue() {
        await this.jobQueue.init({
            [REBUILD_ANCHOR_JOB]: new RebuildAnchorWorker(this.ipfsService, this.handleCommit, this.diagnosticsLogger),
            [HISTORY_SYNC_JOB]: new SyncWorker(this.provider, this.jobQueue, this.chainId, this.diagnosticsLogger, this.syncCompletedForModel.bind(this)),
            [CONTINUOUS_SYNC_JOB]: new SyncWorker(this.provider, this.jobQueue, this.chainId, this.diagnosticsLogger, this.syncCompletedForModel.bind(this)),
        });
    }
    _upsertModelForHistoricSync(model) {
        let existing = this.modelsToHistoricSync.get(model);
        if (existing) {
            existing += 1;
        }
        else {
            existing = 1;
        }
        this.modelsToHistoricSync.set(model, existing);
    }
    async _initModelsToSync() {
        const streamsIds = await this.localIndex.indexedModels();
        for (const id of streamsIds) {
            this.modelsToSync.add(id.toString());
        }
    }
    async _initStateTable() {
        const exists = await this.dataSource.schema.hasTable(STATE_TABLE_NAME);
        if (!exists) {
            await this.dataSource.schema.createTable(STATE_TABLE_NAME, function (table) {
                table.string('processed_block_hash', 1024);
                table.integer('processed_block_number');
            });
            await this.dataSource
                .into(STATE_TABLE_NAME)
                .insert({ processed_block_hash: null, processed_block_number: null });
            return {};
        }
        const state = await this.dataSource.from(STATE_TABLE_NAME).first();
        return {
            processedBlockHash: state['processed_block_hash'],
            processedBlockNumber: state['processed_block_number'],
        };
    }
    _initBlockSubscription(expectedParentHash) {
        this.subscription = createBlockProofsListener({
            confirmations: BLOCK_CONFIRMATIONS,
            chainId: this.chainId,
            provider: this.provider,
            expectedParentHash,
        })
            .pipe(mergeMap((blockProofs) => this._handleBlockProofs(blockProofs)), catchError((err) => {
            this.diagnosticsLogger.err(`Error received during continuous sync: ${err}`);
            throw err;
        }))
            .subscribe();
    }
    async _handleBlockProofs({ block, reorganized }) {
        this.currentBlock = block.number;
        if (reorganized) {
            await this._addSyncJob(HISTORY_SYNC_JOB, {
                jobType: SyncJobType.Reorg,
                fromBlock: block.number - BLOCK_CONFIRMATIONS,
                toBlock: block.number,
                models: Array.from(this.modelsToSync),
            });
        }
        else {
            await this._addSyncJob(CONTINUOUS_SYNC_JOB, {
                jobType: SyncJobType.Continuous,
                fromBlock: block.number,
                toBlock: block.number,
                models: Array.from(this.modelsToSync),
            });
        }
        await this._updateStoredState({
            processedBlockHash: block.hash,
            processedBlockNumber: block.number,
        });
    }
    async _addSyncJob(type, data) {
        if (data.models.length === 0) {
            return;
        }
        if (data.jobType != SyncJobType.Reorg && data.jobType != SyncJobType.Continuous) {
            for (const model of data.models) {
                this._upsertModelForHistoricSync(model);
            }
        }
        const job = type === HISTORY_SYNC_JOB ? createHistorySyncJob(data) : createContinuousSyncJob(data);
        await this.jobQueue.addJob(job);
    }
    async _updateStoredState(state) {
        await this.dataSource.from(STATE_TABLE_NAME).update({
            processed_block_hash: state.processedBlockHash,
            processed_block_number: state.processedBlockNumber,
        });
    }
    async _logSyncStatus() {
        const syncStatus = await this.syncStatus();
        this.diagnosticsLogger.imp(`Logging state of running ComposeDB syncs\n ${JSON.stringify(syncStatus, null, 3)}`);
    }
    async syncStatus() {
        const [activeJobs, pendingJobs] = await Promise.all([
            this.jobQueue.getJobs('active', [CONTINUOUS_SYNC_JOB, HISTORY_SYNC_JOB]),
            this.jobQueue.getJobs('created', [CONTINUOUS_SYNC_JOB, HISTORY_SYNC_JOB]),
        ]);
        const historySyncJobs = activeJobs[HISTORY_SYNC_JOB] || [];
        const continuousSyncJobs = activeJobs[CONTINUOUS_SYNC_JOB] || pendingJobs[CONTINUOUS_SYNC_JOB] || [];
        const pendingSyncJobs = pendingJobs[HISTORY_SYNC_JOB] || [];
        return {
            activeSyncs: historySyncJobs.map((job) => {
                const jobData = job.data;
                return {
                    currentBlock: jobData.currentBlock || jobData.fromBlock,
                    startBlock: jobData.fromBlock,
                    endBlock: jobData.toBlock,
                    models: jobData.models,
                    createdAt: job.createdOn,
                    startedAt: job.startedOn,
                };
            }),
            continuousSync: continuousSyncJobs.length > 0
                ? continuousSyncJobs.map((job) => {
                    const jobData = job.data;
                    return {
                        startBlock: this.startBlock,
                        latestBlock: this.currentBlock,
                        confirmations: BLOCK_CONFIRMATIONS,
                        currentBlock: jobData.fromBlock,
                        models: jobData.models,
                    };
                })
                : [
                    {
                        startBlock: this.startBlock,
                        latestBlock: this.currentBlock,
                        confirmations: BLOCK_CONFIRMATIONS,
                        currentBlock: this.currentBlock - BLOCK_CONFIRMATIONS,
                        models: Array.from(this.modelsToSync),
                    },
                ],
            pendingSyncs: pendingSyncJobs.map((job) => {
                const jobData = job.data;
                return {
                    startBlock: jobData.fromBlock,
                    endBlock: jobData.toBlock,
                    models: jobData.models,
                    createdAt: job.createdOn,
                };
            }),
        };
    }
    _initPeriodicStatusLogger() {
        this.periodicStatusLogger = interval(SYNC_STATUS_LOG_INTERVAL)
            .pipe(concatMap(() => {
            return defer(async () => await this._logSyncStatus());
        }))
            .subscribe();
    }
    async startModelSync(models, syncOptions = {}) {
        if (!this.syncConfig.on)
            return;
        const modelIds = Array.isArray(models) ? models : [models];
        for (const id of modelIds) {
            const modelId = id.toString();
            this.modelsToSync.add(modelId);
        }
        const startBlock = Math.max(this.defaultStartBlock, syncOptions.startBlock || 0);
        const endBlock = !syncOptions.endBlock || syncOptions.endBlock < startBlock
            ? await this.provider.getBlock('latest').then(({ number }) => number - BLOCK_CONFIRMATIONS)
            : syncOptions.endBlock;
        await this._addSyncJob(HISTORY_SYNC_JOB, {
            jobType: SyncJobType.Full,
            fromBlock: startBlock,
            toBlock: endBlock,
            models: modelIds,
        });
    }
    async stopModelSync(models) {
        if (!this.syncConfig.on)
            return;
        const modelIds = Array.isArray(models) ? models : [models];
        for (const id of modelIds) {
            this.modelsToSync.delete(id.toString());
        }
        this.diagnosticsLogger.warn(`Stopped syncing models ${models}. Syncs that are currently running will not be stopped/cancelled but this is a temporary state and will be implemented in a future version.`);
    }
    syncCompletedForModel(data) {
        if (data.jobType !== SyncJobType.Reorg && data.jobType !== SyncJobType.Continuous) {
            const existing = this.modelsToHistoricSync.get(data.modelId);
            if (existing) {
                if (existing <= 1) {
                    this.modelsToHistoricSync.delete(data.modelId);
                }
                else {
                    this.modelsToHistoricSync.set(data.modelId, existing - 1);
                }
            }
        }
    }
    syncComplete(model) {
        const count = this.modelsToHistoricSync.get(model) || 0;
        return count === 0;
    }
    async shutdown() {
        if (!this.syncConfig.on)
            return;
        this.subscription?.unsubscribe();
        this.subscription = undefined;
        this.periodicStatusLogger?.unsubscribe();
        this.periodicStatusLogger = undefined;
        await this.jobQueue.stop();
    }
    get enabled() {
        return Boolean(this.syncConfig.on);
    }
}
//# sourceMappingURL=sync-api.js.map
import { MerkleTreeLoader } from '../utils.js';
import { StreamID } from '@ceramicnetwork/streamid';
import { REBUILD_ANCHOR_JOB, } from '../interfaces.js';
import { CID } from 'multiformats/cid';
import { pathString } from '@ceramicnetwork/anchor-utils';
import PQueue from 'p-queue';
const IPFS_LOAD_CONCURRENCY = 16;
const REBUILD_ANCHOR_JOB_OPTIONS = {
    retryLimit: 5,
    retryDelay: 60,
    retryBackoff: true,
    expireInHours: 12,
    retentionDays: 3,
};
export function createRebuildAnchorJob(proof, models, options = REBUILD_ANCHOR_JOB_OPTIONS) {
    return {
        name: REBUILD_ANCHOR_JOB,
        data: {
            models,
            chainId: proof.chainId,
            txHash: proof.txHash.toString(),
            root: proof.root.toString(),
            txType: proof.txType,
        },
        options,
    };
}
export class RebuildAnchorWorker {
    constructor(ipfsService, handleCommit, logger) {
        this.ipfsService = ipfsService;
        this.handleCommit = handleCommit;
        this.logger = logger;
    }
    async getModelForStream(streamId) {
        const signedCommit = await this.ipfsService.retrieveCommit(streamId.cid, streamId);
        const genesisCommit = signedCommit?.link
            ? await this.ipfsService.retrieveCommit(signedCommit.link, streamId)
            : signedCommit;
        if (!genesisCommit?.header?.model) {
            return null;
        }
        return StreamID.fromBytes(genesisCommit.header.model);
    }
    async handler(job) {
        const jobData = job.data;
        const proof = {
            chainId: jobData.chainId,
            txHash: CID.parse(jobData.txHash),
            root: CID.parse(jobData.root),
            txType: jobData.txType,
        };
        const proofCid = await this.ipfsService.storeRecord(proof).catch((err) => {
            this.logger.err(`Failed to store a proof on ipfs for root ${jobData.root} and txHash ${jobData.txHash} for models ${jobData.models} with error: ${err} `);
        });
        if (!proofCid) {
            return;
        }
        const merkleTreeLeafLoader = new MerkleTreeLoader(this.ipfsService, proof.root);
        const metadata = await merkleTreeLeafLoader.getMetadata().catch((err) => {
            this.logger.err(`Failed to retrieve the merkle tree metadata for root ${jobData.root} and txHash ${jobData.txHash} for models ${jobData.models} with error: ${err} `);
        });
        if (!metadata) {
            return;
        }
        const tasks = metadata.streamIds.map((stream, i) => {
            return async () => {
                try {
                    const streamId = StreamID.fromString(stream);
                    const model = await this.getModelForStream(streamId);
                    const shouldIndex = model
                        ? jobData.models.some((modelNeedingSync) => modelNeedingSync === model.toString())
                        : false;
                    if (shouldIndex) {
                        const { cid, path } = await merkleTreeLeafLoader.getLeafData(i);
                        const anchorCommit = {
                            id: streamId.cid,
                            prev: cid,
                            proof: proofCid,
                            path: pathString(path),
                        };
                        const anchorCommitCid = await this.ipfsService.storeCommit(anchorCommit);
                        await this.handleCommit(streamId, anchorCommitCid, model);
                        this.logger.debug(`Successfully handled anchor commit ${anchorCommitCid} for stream ${streamId.toString()} and model ${model.toString()} using merkle tree root ${jobData.root}`);
                    }
                }
                catch (err) {
                    this.logger.err(`Failed to recreate the anchor commit for stream ${stream} using root ${jobData.root} and txHash ${jobData.txHash} for models ${jobData.models} with error: ${err} `);
                }
            };
        });
        const queue = new PQueue({ concurrency: IPFS_LOAD_CONCURRENCY });
        await queue.addAll(tasks);
        this.logger.debug(`Rebuild anchor job completed for models ${jobData.models}, root ${jobData.root}, and txHash ${jobData.txHash}`);
    }
}
//# sourceMappingURL=rebuild-anchor.js.map